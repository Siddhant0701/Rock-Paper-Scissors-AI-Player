{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahaj\\AppData\\Roaming\\Python\\Python39\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from time import process_time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # FATAL\n",
    "os.environ[\"GLOG_minloglevel\"] =\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict ={\n",
    "    0: \"WRIST\",\n",
    "    1: \"THUMB_CMC\",\n",
    "    2: \"THUMB_MCP\",\n",
    "    3: \"THUMB_IP\",\n",
    "    4: \"THUMB_TIP\",\n",
    "    5: \"INDEX_FINGER_MCP\",\n",
    "    6: \"INDEX_FINGER_PIP\",\n",
    "    7: \"INDEX_FINGER_DIP\",\n",
    "    8: \"INDEX_FINGER_TIP\",\n",
    "    9:  \"MIDDLE_FINGER_MCP\",\n",
    "    10: \"MIDDLE_FINGER_PIP\",\n",
    "    11: \"MIDDLE_FINGER_DIP\",\n",
    "    12: \"MIDDLE_FINGER_TIP\",\n",
    "    13: \"RING_FINGER_MCP\",\n",
    "    14: \"RING_FINGER_PIP\",\n",
    "    15: \"RING_FINGER_DIP\",\n",
    "    16: \"RING_FINGER_TIP\",\n",
    "    17: \"PINKY_MCP\",\n",
    "    18: \"PINKY_PIP\",\n",
    "    19: \"PINKY_DIP\",\n",
    "    20: \"PINKY_TIP\",\n",
    "}\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands( \n",
    "    static_image_mode= True,\n",
    "    max_num_hands = 3,\n",
    "    min_detection_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transform the image to a vector with 21 coordinates.\n",
    "def image_to_vector(img):\n",
    "    try:\n",
    "        result_vector =[]\n",
    "        result = hands.process(img)\n",
    "\n",
    "        for hand_landmark in result.multi_hand_world_landmarks:\n",
    "            for item in dict:\n",
    "                landmarkObj = hand_landmark.landmark[mp_hands.HandLandmark[dict[item]]]\n",
    "                result_vector.append([landmarkObj.x,landmarkObj.y, landmarkObj.z])\n",
    "        \n",
    "        return np.array(result_vector, dtype=np.float64)\n",
    "    \n",
    "    except:\n",
    "        return np.reshape(np.zeros(63, dtype=np.float64), (21,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeData(data):\n",
    "    for i in range(len(data)):\n",
    "        data[i] = (data[i] - np.min(data[i])) / (np.max(data[i]) - np.min(data[i]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset\n",
    "(train_images,train_labels) = tfds.as_numpy(tfds.load('rock_paper_scissors', split='train[:70%]', batch_size=-1, as_supervised = True))\n",
    "(validation_images,validation_labels) = tfds.as_numpy(tfds.load('rock_paper_scissors', split='train[70%:]', batch_size=-1, as_supervised = True))\n",
    "(test_images,test_labels) = tfds.as_numpy(tfds.load('rock_paper_scissors', split='test', batch_size=-1, as_supervised = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the images to vectors\n",
    "train_map = map(image_to_vector, train_images)\n",
    "test_map = map(image_to_vector, test_images)\n",
    "validation_map = map(image_to_vector, validation_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_data = np.array(list(train_map))\n",
    "raw_test_data = np.array(list(test_map))\n",
    "raw_validation_data = np.array(list(validation_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_data = np.reshape(raw_train_data, (-1, 63))\n",
    "raw_test_data = np.reshape(raw_test_data, (-1, 63))\n",
    "raw_validation_data = np.reshape(raw_validation_data, (-1, 63))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check where sum of a row is not 0\n",
    "train_data, train_labels =  raw_train_data[np.where(np.sum(raw_train_data, axis=1) != 0)], train_labels[np.where(np.sum(raw_train_data, axis=1) != 0)]\n",
    "test_data, test_labels =  raw_test_data[np.where(np.sum(raw_test_data, axis=1) != 0)], test_labels[np.where(np.sum(raw_test_data, axis=1) != 0)]\n",
    "validation_data, validation_labels =  raw_validation_data[np.where(np.sum(raw_validation_data, axis=1) != 0)], validation_labels[np.where(np.sum(raw_validation_data, axis=1) != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normalized = NormalizeData(train_data)\n",
    "test_normalized = NormalizeData(test_data)\n",
    "validation_normalized = NormalizeData(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('loss') < 0.01):\n",
    "            print(\"\\nReached 1% loss so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', input_shape=(63,)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.0272 - accuracy: 0.9929 - val_loss: 0.0128 - val_accuracy: 0.9973\n",
      "Epoch 2/20\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.0326 - accuracy: 0.9905 - val_loss: 0.0175 - val_accuracy: 0.9973\n",
      "Epoch 3/20\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.0251 - accuracy: 0.9929 - val_loss: 0.0215 - val_accuracy: 0.9959\n",
      "Epoch 4/20\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.0447 - accuracy: 0.9929 - val_loss: 0.0145 - val_accuracy: 0.9973\n",
      "Epoch 5/20\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.0234 - accuracy: 0.9952 - val_loss: 0.0159 - val_accuracy: 0.9973\n",
      "Epoch 6/20\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.0274 - accuracy: 0.9935 - val_loss: 0.0119 - val_accuracy: 0.9986\n",
      "Epoch 7/20\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.0241 - accuracy: 0.9923 - val_loss: 0.0600 - val_accuracy: 0.9767\n",
      "Epoch 8/20\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.0224 - accuracy: 0.9941 - val_loss: 0.0184 - val_accuracy: 0.9973\n",
      "Epoch 9/20\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.0364 - accuracy: 0.9935 - val_loss: 0.0180 - val_accuracy: 0.9973\n",
      "Epoch 10/20\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.0142 - val_accuracy: 0.9986\n",
      "Epoch 11/20\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.0223 - accuracy: 0.9941 - val_loss: 0.0134 - val_accuracy: 0.9986\n",
      "Epoch 12/20\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.0280 - accuracy: 0.9941 - val_loss: 0.0158 - val_accuracy: 0.9986\n",
      "Epoch 13/20\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.0139 - accuracy: 0.9946 - val_loss: 0.0132 - val_accuracy: 0.9986\n",
      "Epoch 14/20\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.0192 - accuracy: 0.9964 - val_loss: 0.0181 - val_accuracy: 0.9986\n",
      "Epoch 15/20\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.0229 - accuracy: 0.9958 - val_loss: 0.0111 - val_accuracy: 0.9986\n",
      "Epoch 16/20\n",
      "164/169 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9988\n",
      "Reached 1% loss so cancelling training!\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0188 - val_accuracy: 0.9959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d90439c3a0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_normalized, train_labels, epochs=20, batch_size=10, callbacks=[myCallback()], validation_data=(validation_normalized, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369/369 [==============================] - 1s 3ms/step - loss: 0.1097 - accuracy: 0.9729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1097118929028511, 0.9728997349739075]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_normalized, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_weights.h5')\n",
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
